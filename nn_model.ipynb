{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python [conda env:py_tf]",
      "language": "python",
      "name": "conda-env-py_tf-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "nn_model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-04-25T16:12:19.790806Z",
          "start_time": "2021-04-25T16:12:18.253149Z"
        },
        "id": "IqJAS7iBivln"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import gzip\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from config import RAW_DIR, PRE_DIR, RES_DIR\n",
        "from utils.data_porter import read_from_csv, save_to_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uJYXNluivlo"
      },
      "source": [
        "with open(os.path.join(PRE_DIR, 'review_data.pkl'), 'rb') as f:\n",
        "    review_data = pickle.load(f)\n",
        "print(review_data.shape)\n",
        "review_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NX8n5bgQivlp"
      },
      "source": [
        "review_data['reviewTime'].max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWIIYe2Rivlp"
      },
      "source": [
        "review_data['reviewTime'].min()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TNNL4buivlq"
      },
      "source": [
        "# Key word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NbRVjY_ivlq"
      },
      "source": [
        "import "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "code_folding": [],
        "id": "GWIG4NW8ivlq"
      },
      "source": [
        "# NLP data processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a5Szdm6ivlr"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "# Add manually\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "english_stemmer=nltk.stem.SnowballStemmer('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEfykGf2ivlr"
      },
      "source": [
        "def data_clean(rev, remove_stopwords=True): \n",
        "    \n",
        "    try:\n",
        "        new_text = re.sub(\"[^a-zA-Z]\",\" \", rev)\n",
        "    except:\n",
        "        print(rev)\n",
        "        new_text = []\n",
        "   \n",
        "    words = new_text.lower().split()\n",
        "    \n",
        "    if remove_stopwords:\n",
        "        sts = set(stopwords.words(\"english\"))\n",
        "        words = [w for w in words if not w in sts]\n",
        "    ary=[]\n",
        "    eng_stemmer = english_stemmer \n",
        "    for word in words:\n",
        "        ary.append(eng_stemmer.stem(word))\n",
        "\n",
        "    new_ary = ' '.join(ary)\n",
        "    return(new_ary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w94iL-06ivls"
      },
      "source": [
        "review_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATYPw0iZivls"
      },
      "source": [
        "part_data = review_data.sample(frac=0.1, random_state=1).fillna('')\n",
        "part_data = part_data.drop(columns=['vote', 'style', 'image', 'reviewTime', 'reviewerName', 'verified'])\n",
        "part_data = part_data.sort_values(by='unixReviewTime')\n",
        "print(part_data.shape)\n",
        "part_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH6iaMLnivls"
      },
      "source": [
        "# part_data['reviewText'] = part_data['reviewText'].apply(lambda x: data_clean(x))\n",
        "# part_data['summary'] = part_data['summary'].apply(lambda x: data_clean(x))\n",
        "\n",
        "# part_data['docs'] = part_data.apply(lambda x: x.reviewText + x.summary, axis=1)\n",
        "\n",
        "\n",
        "part_data['docs'] = part_data.apply(lambda x: data_clean(x.reviewText) + data_clean(x.summary), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1xQn94bivlt"
      },
      "source": [
        "part_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whZkSRYnivlt"
      },
      "source": [
        "part_data['overall'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkUqUvE6ivlt"
      },
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtTbs8Pbivlu"
      },
      "source": [
        "corpus = part_data['reviewText'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qUDhPFXivlu",
        "outputId": "c75a2b85-09e4-4024-a88e-c26f15a4516a"
      },
      "source": [
        "vectorizer = TfidfVectorizer(min_df=20, max_df=0.5, max_features=2000)\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48421, 2000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQaR4WJRivlu"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qrj6tAzivlu"
      },
      "source": [
        "train_x = X[: int(X.shape[0] * 0.8)]\n",
        "val_x = X[int(X.shape[0] * 0.8): int(X.shape[0] * 0.9)]\n",
        "test_x = X[int(X.shape[0] * 0.9) :]\n",
        "print(f\"train_x: {train_x.shape}\")\n",
        "print(f\"val_x: {val_x.shape}\")\n",
        "print(f\"test_x: {test_x.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0fbg3LBivlv"
      },
      "source": [
        "y_encode = {\n",
        "    1: [1, 0, 0, 0, 0],\n",
        "    2: [0, 1, 0, 0, 0],\n",
        "    3: [0, 0, 1, 0, 0],\n",
        "    4: [0, 0, 0, 1, 0],\n",
        "    5: [0, 0, 0, 0, 1]\n",
        "}\n",
        "part_data['y'] = part_data['overall'].apply(lambda x: y_encode[x])\n",
        "\n",
        "train_y = np.array(part_data['y'][: int(X.shape[0] * 0.8)].tolist())\n",
        "val_y = np.array(part_data['y'][int(X.shape[0] * 0.8): int(X.shape[0] * 0.9)].tolist())\n",
        "test_y = np.array(part_data['y'][int(X.shape[0] * 0.9) :].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kcbe6qNMivlv"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=train_x.shape[1]))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(128, input_dim=train_x.shape[1]))\n",
        "model.add(Dropout(rate=0.2))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWbR_EUYivlv"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10,\n",
        "    mode='auto', restore_best_weights=False\n",
        ")# verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5CdlGz4ivlw"
      },
      "source": [
        "model.fit(train_x, train_y,\n",
        "          validation_data=(val_x, val_y),\n",
        "          epochs=100,\n",
        "          batch_size=64,\n",
        "          verbose=1, \n",
        "          callbacks=[callback])\n",
        "\n",
        "model.evaluate(test_x, test_y)[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnx392H8ivlw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}